---
layout: default
title: Computer Vision in the Built Environment 
description: CV4AEC @ CVPR 2024
---

:wave: Welcome to the **4<sup>th</sup> Workshop and Challenge on
Computer Vision In The Built Environment For The Design, Construction and Operation of Buildings** organized at :wave: [<img class="rounded-rect" src="assets/imgs/cvpr2024.png" width="400px" alt="cvpr2024"/>](https://cvpr.thecvf.com/) 
{: .text-center} 

Building on the success of the previous three workshops, the 4th Workshop on Computer Vision in the Built Environment continues on connecting the domains of Architecture, Engineering, and Construction (AEC) with that of Computer Vision by establishing a common ground of interaction and identify shared research interests. Specifically, this workshop focuses on the as-is semantic status of built environments and the changes that take place within them over time. These topics will be presented from the dual lens of Computer Vision and AEC-FM, highlighting the limitations and bottlenecks related to developing applications for this specific domain. The objective is for attendees to learn more about AEC-FM and the variety of real-world problems that, if solved, could have a tangible impact on this multi trillion dollar industry as well as the overall quality of life across the globe.

The workshop will begin by establishing ways to capture the as-is status of a space with expert speakers from both the AEC and Computer Vision domains. Attendees will be then introduced to the type of information required for the spatiotemporal analysis of our built environment in AEC, with a focus on effective management, safety, and the role of users in this process. Following that, the topic of scene understanding from 3D and 4D reconstructions will be presented. Finally, to close the loop from understanding real-world built environments to designing built environments better and faster, the topic of scene synthesis at a geometric and semantic level will be presented. The importance of closing the loop for the AEC industry is paramount, especially when considering the design paradox. Architects are designing living spaces without any feedback from their previous designs. Learning to design using data from spaces that are already occupied and in-use, can provide designers with insights on what makes spaces appropriate for supporting the quality of life of the users.

To further establish connections between the two domains and identify what we can do right now and what is still hard to solve, we will host the **4th International Scan-to-BIM competition** targeted on acquiring the semantic as-is status of buildings given their 3D point clouds. Specifically, we will focus on the tasks of floorplan reconstruction and 3D building model reconstruction and present appropriate interdisciplinary metrics for solving them. The past two years we observed that a large gap remains before these problems can be considered solved and actually meet the needs of practitioners. We regard this workshop as the ideal environment for understanding the challenges and steps forward given that it provides convergence between the research and practical communities from multiple disciplines.

---

## :newspaper: **News** {#news}
- **14 Feb 2024 ---** :loudspeaker: We are accepting paper submissions this year! Look at Important Dates and Call For Short Papers, [CMT Submission Link](https://cmt3.research.microsoft.com/CV4AEC2024/).
- **14 Feb 2024 ---** :loudspeaker: **Caitlin Mueller** confirmed as keynote speaker.
- **13 Feb  2024 ---** :loudspeaker: Tentative schedule and dates released.
- **26 Jan 2024 ---** :loudspeaker: **Catherine De Wolf** and **Francis Engelmann** confirmed as keynote speaker.
- **26 Jan 2024 ---** :loudspeaker: **Derek Lichti** and **Yuanbo (Amber) Xiangli** confirmed as keynote speaker.
- **26 Jan 2024 ---** :tada: Website is live!


---

## :hourglass_flowing_sand: **Important Dates** {#dates}
> **NOTE**: The submission/release times are **11:59:59 UTC** on the specified date.

<strong><u>Short Paper Submission</u></strong>
- **1 Apr 2024 ---** Paper submission deadline
- **3 Apr 2024 ---** Papers distributed to reviewers
- **18 Apr 2024 ---** Review submission deadline
- **25 Apr 2024 ---** Notification to Authors

<strong><u>Challenge</u></strong>
- **12 Mar 2024 ---** Training + Validation + Testing data available for 2D 
- **14 Mar 2024 ---** Training + Testing data available for 3D
- **18 Mar 2024 ---** Evaluation server **open** to evaluate test submissions
- **25 May 2024 ---** Challenge Submission Deadline
- **01 Jun 2024 ---** Notification To Challenge Participants
- **18 Jun 2024 ---** CV4AEC Workshop @ CVPR 2024

---

## :calendar: **Schedule** {#schedule}
The workshop will take place on **18 June 2023** from **09:00 - 17:00 PDT**.
> **NOTE**: Times are shown in **Pacific Daylight Time**. Please take this into account if joining the workshop virtually.

| Time (PDT)    | Duration | Event                                                                  |
|---------------|----------|------------------------------------------------------------------------|
| 09:00 - 09:30 | 30 mins  | Welcome & Introduction                                                 |
| 09:30 - 10:00 | 30 mins  | Keynote Speaker #1                                                     |
| 10:00 - 10:30 | 30 mins  | Keynote Speaker #2                                                     |
| 10:30 - 11:00 | 30 mins  | Keynote Speaker #3                                                     |
| 11:00 - 11:15 | 30 mins  | _Coffee Break_                                                         |
| 11:15 - 11:45 | 30 mins  | Keynote Speaker #4                                                     |
| 11:45 - 12:45 | 60 mins  | Oral Session                                                           |
| 12:45 - 14:15 | 90 mins  | Poster Session & _Lunch Break_                                         | 
| 14:15 - 14:45 | 30 mins  | Challenge Winner Presentations and Awards                              |
| 14:45 - 15:15 | 30 mins  | Keynote Speaker #5                                                     |
| 15:15 - 15:45 | 30 mins  | Keynote Speaker #6                                                     |
| 15:45 - 16:45 | 60 mins  | _Panel Discussion_                                                     |
| 16:45 - 17:00 | 15 mins  | _Concluding Remarks_                                                   |

---

## :microphone: **Keynote Speakers** {#speakers}

<div class="container">

<figure>
    <a href="https://www.catherinedewolf.com/">
    <img class="img-author" src="assets/imgs/authors/cvpr2024/catherinedewolf.jpeg" alt="Catherine De Wolf"/></a>
    <b><br><a href="https://www.catherinedewolf.com/">Catherine De Wolf</a>
    <br>Professor, CEE <br>ETH Zurich</b>
</figure>

<figure>
    <a href="https://francisengelmann.github.io/">
    <img class="img-author" src="assets/imgs/authors/cvpr2024/francisengelmann.jpeg" alt="Francis Engelmann" > </a>
    <b><br><a href="https://francisengelmann.github.io/">Francis Engelmann</a>
    <br>PostDoc, CS <br>ETH Zurich</b>
</figure>

<figure>
    <a href="https://www.geo-week.com/advisor/derek-lichti/">
    <img class="img-author" src="assets/imgs/authors/cvpr2024/dereklichti.jpeg" alt="Derek Lichti"/></a>
    <b><br><a href="https://www.geo-week.com/advisor/derek-lichti/">Derek Lichti</a>
    <br>Professor, Geomatics <br>University of Calgary</b>
</figure>

<figure>
    <a href="https://cee.mit.edu/people_individual/caitlin-mueller/">
    <img class="img-author" src="assets/imgs/authors/cvpr2024/caitlinmueller.jpeg" alt="Caitlin Mueller"/></a>
    <b><br><a href="https://cee.mit.edu/people_individual/caitlin-mueller/">Caitlin Mueller</a>
    <br>Professor, CEE<br>MIT</b>
</figure>

<figure>
    <a href="https://kam1107.github.io/">
    <img class="img-author" src="assets/imgs/authors/cvpr2024/yuanboxiangli.jpeg" alt="Yuanbo (Amber) Xiangli"/></a>
    <b><br><a href="https://kam1107.github.io/">Yuanbo (Amber) Xiangli</a>
    <br>Postdoc, CS <br>Cornell</b>
</figure>

</div>


[**Catherine De Wolf**](https://www.catherinedewolf.com/)
is assistant professor and director of the Chair of Circular Engineering for Architecture (CEA) at ETH Zurich. Her work explores digital innovations such as reality capture and AI to advance the built environment towards a circular economy. She has a dual background in civil engineering and architecture and  completed her PhD at MIT. She is on the steering committee of the Centre for Augmented Computational Design in Architecture, Engineering and Construction (Design++). Catherine is also a faculty at the AI Center, EMPA, the Future Cities Lab, and the National Centre of Competence in Research on Digital Fabrication (DFAB). Additionally, Catherine provides regular consultation on environmental impact assessments for both government entities like the European Commission and engineering design offices such as Arup. Throughout her career, she has gained international experience working at institutions like the University of Cambridge, TU Delft, EPFL, Nanjing University, Kuwait University, and the African Urban Metabolism Network. Her contributions to these projects were often made possible by securing multiple fellowships, including the Swiss Excellence, WBI World Excellence, and Marie Sklodowska-Curie Postdoctoral Fellowships. 

[**Francis Engelman**](https://francisengelmann.github.io/)
is a PostDoc with Prof. Marc Pollefeys at ETH Zurich, and a visiting researcher at Google with Federico Tombari. His research interest lie at the intersection of computer vision and deep learning towards open-vocabulary 3D scene understanding with foundation models.
Francis is a Fellow of the ETH AI Center, the ELLIS Society, and the recipient of the ETHZ Career Seed Award. 

[**Derek Lichti**]("https://www.geo-week.com/advisor/derek-lichti/") 
is a Professor of Civil Engineering and Computer Science & Technology. Derek Lichti received his Bachelor’s degree in Survey Engineering from Toronto Metropolitan University in 1993 and MSc and PhD degrees in Geomatics Engineering from the University of Calgary in 1996 and 1999, respectively. He is currently Professor in the Department of Geomatics Engineering at the University of Calgary, which he joined in 2008 and served (2013-2018) as Department Head. He is currently ISPRS Congress Director and served (2013-2020) as Editor-in-Chief of the ISPRS Journal of Photogrammetry and Remote Sensing. His research program focuses on imaging metrology: precision 3D reality capture from imaging sensors, principally terrestrial laser scanners and digital cameras. It touches a wide range of applications including the documentation of at-risk cultural heritage sites, as-built modelling of industrial sites, wear and damage assessment in structures and industrial machinery, and dimensional control.

[**Caitlin Mueller**](https://cee.mit.edu/people_individual/caitlin-mueller/) is a researcher, designer, and educator working at the interface of architecture and structural engineering. She is currently an Assistant Professor in the Building Technology Program, where she leads the Digital Structures research group. As a researcher, Mueller focuses on developing new computational methods and tools for synthesizing architectural and structural intentions in early-stage design. She also works in the field of digital fabrication, with a focus on linking high structural performance with new methods of architectural making. In addition to her digital work, she conducts research on the nature of collaboration between architects and engineers from a historical perspective. Mueller also aims for interdisciplinary learning and integration in her teaching efforts, which include subjects in structural design and computational methods.

[**Yuanbo (Amber) Xiangli**](https://kam1107.github.io/)
is a postdoc scholar at Cornell University, working with Prof. Noah Snavely. Prior to this, she did her Ph.D at Multimedia Lab, the Chinese University of Hong Kong, supervised by Prof. Dahua Lin. She received her Master degree from University of Oxford and Diploma from the University of Nottingham in Computer Science. Her research interests lie in 3D computer vision and generative modelling. She has been working on photorealistic and efficient large-scale 3D indoor/outdoor scenes rendering, manipulation and generation, leveraging diverse 2D/3D data sources, geographic and architectural information. 



## :paperclip: **Call for Short Papers** {#papers}
This year we are inviting as part of the workshop the submission of short papers, which will not appear in the conference proceedings. Accepted papers will be presented in an oral session and will also have a spot in the poster session. 

Short papers range from 3 to 4 pages without references. Submissions should otherwise follow the CVPR 2024 Author Kit provided by the main conference: [CVPR 2024 Auhtor Kit](https://github.com/cvpr-org/author-kit/releases). Papers that are not properly anonymized, or do not use the template, or have more than four pages (excluding references) will be considered for rejection without review.

Link to the submission system : [CMT](https://cmt3.research.microsoft.com/CV4AEC2024/)

Submissions should:
- Introduce the topic and literature review, discussion on methodology, preliminary results.
- Motivate and place the topic in relation to the built environment and its specific application, including a comparison to current AEC practice
- Include a short discussion on considerations of practice, ethics, and organizations, as applicable.

<strong> Topics </strong>: Any topic that can be categorized as Computer Vision applications In The Built Environment For The Design, Construction and Operation of Buildings.

Including but not limited to:
- Generative design
- Floorplan reconstruction
- Indoor layout synthesis
- Activity recognition (e.g., occupants in a building, workers in a construction site)
- Semantic 3D understanding (e.g., for renovation or construction)
- 3D reconstruction (e.g., for renovation or construction)
- Material understanding
- Object/Scene localization
- Scene completion
- Change detection
- And more

---

## :checkered_flag: **Challenge** {#challenge}
The workshop will host the 3rd International Scan-to-BIM challenge. The challenge will include the following tasks:

I. 2D Floorplan Reconstruction \
II. 3D Building Model Reconstruction

### 2D Floor Plan Reconstruction

The 2D Floorplan Reconstruction challenge contains a total of 31 buildings with multiple floors each and dozens of rooms on each floor. Of which, 20 buildings are designated as the training set, with a total of 49 point clouds. The validation and testing sets contain 5.5 buildings with 21 point clouds each. For each model, there is an aligned point cloud in LAZ format. For the training and validation sets, a corresponding floorplan aligned with the coordinate system of the point cloud is also provided. The 2D challenge will be released soon. We have provided a **[Github repository](https://github.com/cv4aec/2d-floorplan-eval)** containing the evaluation code and metrics for floorplan reconstruction. The submission should be made in the same JSON format as in the provided ground truth. We include metrics to evaluate the reconstruction of the walls, doors, and columns, as well as floor area in 2D : 

1. **Geometric Metrics** \
    a. _IoU_ of each room (a room is defined as a completely separated area with walls and doors). \
    b. _Accuracy of endpoints_ : Precision/Recall at 3 different thresholds: 5cm, 10cm and 20cm, as well as the F-measure at each threshold will be evaluated in the coordinate system of the point cloud. The provided endpoints will be matched with the Hungarian algorithm to the point cloud, and every point that is within a certain threshold will be determined as a match. \
    c. _Orientation_ For each matched line between the ground truth, we will compute the cosine similarity metric between them as the normalized dot product. If a line is not matched with ground truth, the cosine metric will be zero. Finally, the metric will be averaged over all the ground truth lines.

2. **Topological Metrics** \
    a. _[Warping error](https://ieeexplore.ieee.org/document/5539950)_ : The warping error will first warp the predicted floorplan to the ground truth with a homotopic deformation, and then compute the pixels that cannot match after the deformation. \
    b. **_Betti number error_** : The Betti number error will compare the Betti numbers between the prediction and the ground truth and output the absolute value of the difference.

### 3D Building Model Reconstruction

The training data consists of 18 floors from 10 buildings. For each model, there is an aligned point cloud in LAZ format. The 3D building coordinates for walls, columns and doors are presented in 3 separate JSON files. We focus on the reconstruction of walls, columns, and doors. The 3D challenge will be released soon. We have provided a **[Github repository](https://github.com/cv4aec/3d-matching-eval)** containing the evaluation code and metrics for building model reconstruction. The submission should be made in the same JSON format as in the provided ground truth. We evaluate the submissions on a variety of metrics : 

1. **3D IoU** of the 3D bounding box of each wall
2. **Accuracy of the endpoints** : Precision/Recall at 3 different thresholds: 5cm, 10cm and 20cm, as well as F-measure will be evaluated in the coordinate system of the point cloud. The provided endpoints will be matched with the Hungarian algorithm to the point cloud, and every point that is within a certain threshold will be determined as a match. We evaluate per each of the three semantic types (i.e., wall, column, door).

> We would like to note that ALL the submissions **need to be constructed automatically** . Manual reconstructions are against the spirit of this challenge and will not be allowed.

---

## :trophy: **Challenge Winners** {#winners}
> TBA!

---

## :question: **Questions** {#questions}
Contact the organisers at **[cv4aec.3d@gmail.com](mailto:cv4aec.3d@gmail.com)**

---
# **Organizers** {#organizers}
## :construction_worker: **Senior Organizers** {#senior-organizers}
<div class="container">
<figure>
    <a href="https://ir0.github.io/">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/iroarmeni.jpg" alt="Iro Armeni"/></a>
    <b><br><a href="https://ir0.github.io/">Iro Armeni</a>
    <br>Professor, CEE  <br> Stanford</b>
</figure>

<figure>
    <a href="https://www.linkedin.com/in/erzhuo-ezra-che-40888137/">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/erzhuoche.jpeg" alt="Iro Armeni"/></a>
    <b><br><a href="https://www.linkedin.com/in/erzhuo-ezra-che-40888137/">Erzhuo Che</a>
    <br>Assistant Professor (Senior Research), CEE <br> Oregon State</b>
</figure>

<figure>
    <a href="https://web.stanford.edu/~fischer/">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/martinfischer.jpg" alt="Martin Fischer"/></a>
    <b><br><a href="https://web.stanford.edu/~fischer/">Martin Fischer</a>
    <br>Professor, CEE <br> Stanford</b>
</figure>

<figure>
    <a href="https://fcl.ethz.ch/people/Module-Lead/daniel-hall.html#:~:text=Dr%20Daniel%20Hall%20is%20co,Geomatic%20Engineering%20at%20ETH%20Z%C3%BCrich.">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/danielhall.jpeg" alt="Daniel Hall"/></a>
    <b><br><a href="https://fcl.ethz.ch/people/Module-Lead/daniel-hall.html#:~:text=Dr%20Daniel%20Hall%20is%20co,Geomatic%20Engineering%20at%20ETH%20Z%C3%BCrich.">Daniel Hall</a>
    <br>Assistant Professor, CEE <br> ETHZ</b>
</figure>

<figure>
    <a href="https://research.engr.oregonstate.edu/geomatics/faculty-members">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/jaehoonjung.jpeg" alt="Jaehoon Jung"/></a>
    <b><br><a href="https://research.engr.oregonstate.edu/geomatics/faculty-members">Jaehoon Jung</a>
    <br>Assistant Professor (Senior Research), CEE <br> Oregon State</b>
</figure>

<figure>
    <a href="http://web.engr.oregonstate.edu/~lif/">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/fuxinli.jpg" alt="Fuxin Li"/></a>
    <b><br><a href="http://web.engr.oregonstate.edu/~lif/">Fuxin Li</a>
    <br>Associate Professor, CS <br> Oregon State</b>
</figure>

<figure>
    <a href="https://directory.forestry.oregonstate.edu/people/olsen-michael">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/michaelolsen.jpg" alt="Michael Olsen"/></a>
    <b><br><a href="https://directory.forestry.oregonstate.edu/people/olsen-michael">Michael Olsen</a>
    <br>Associate Professor, CEE <br> Oregon State</b>
</figure>

<figure>
    <a href="https://people.inf.ethz.ch/pomarc/">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/marcpollefeys.jpeg" alt="Marc Pollefeys"/></a>
    <b><br><a href="https://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a>
    <br>Professor, CS <br> ETHZ</b>
</figure>

<figure>
    <a href="https://cce.oregonstate.edu/turkan">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/yeldaturkan.jpg" alt="Yelda Turkan"/></a>
    <b><br><a href="https://cce.oregonstate.edu/turkan">Yelda Turkan</a>
    <br>Assistant Professor, CEE <br> Oregon State</b>
</figure>

<figure>
    <a href="https://www.linkedin.com/in/heidar-rastiveis/">
    <img class="img-author" src="assets/imgs/authors/cvpr2024/heidarrastiveis.jpg" alt="Heidar Rastiveis"/></a>
    <b><br><a href="https://www.linkedin.com/in/heidar-rastiveis/">Heidar Rastiveis</a>
    <br>Assistant Professor (Senior Research), CEE <br> Oregon State</b>
</figure>


</div>

## :grimacing: **Student Organizers** {#student-organizers}
<div class="container">
<figure>
    <a href="https://sayandebsarkar.com/">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/sayandebsarkar.jpg" alt="Sayan Deb Sarkar"/></a>
    <b><br><a href="https://sayandebsarkar.com/">Sayan Deb Sarkar</a>
    <br>MSc CS <br> ETHZ</b>
</figure>

<figure>
    <a href="https://antonskoltech.github.io/">
    <img class="img-author" src="assets/imgs/authors/cvpr2023/antonegorov.jpeg" alt="Anton Egorov"/></a>
    <b><br><a href="https://antonskoltech.github.io/">Anton Egorov</a>
    <br>Research Assistant <br> Oregon State </b>
</figure>

<figure>
    <a href="https://www.linkedin.com/in/mohsen-arjmand-591388b9/">
    <img class="img-author" src="assets/imgs/authors/cvpr2024/mohsenarjmand.jpg" alt="Mohsen Arjmand"/></a>
    <b><br><a href="https://www.linkedin.com/in/mohsen-arjmand-591388b9/">Mohsen Arjmand</a>
    <br>PhD, CEE <br> Oregon State</b>
</figure>

</div>
