<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Computer Vision in the Built Environment</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>
    <!-- Custom styles for this template -->
    <link href="css/agency.min.css" rel="stylesheet">
    <link rel="stylesheet" href="css/table.css">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="index.html">Computer Vision in the Built Environment</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav text-uppercase ml-auto text-center">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#description">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#challenge">Challenge</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#schedule">Schedule</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#speakers">Speakers</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#organizers">Organizers</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="https://cv4aec.github.io/index_2021.html">Previous Workshops</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Header -->
    <header class="masthead">
      <div class="container">
        <div class="intro-text">
          <div class="intro-lead-in">2nd Workshop and Challenge on</div>
          <div class="intro-heading text-uppercase"><span style="font-weight:600">Computer Vision in the Built Environment</span><br> <span style="text-transform:lowercase;font-style:italic">for the</span> Design, Construction, <span style="text-transform:lowercase;font-style:italic">and</span> Operation of Buildings</div>
          
          <div class="intro-lead-in" style="margin-bottom:0px;padding-bottom:0px;">June 19th 2022, Full Day Workshop</div> 

          <p style="margin-top:50px;color:red"><i>Latest Update from the Conference Organizers:
            <br> <i>5/16/22: <a href="#challenge">Challenge information</a> updated! </i></br>
            <br>"Unless the epidemiological situation changes drastically, CVPR 2022 will be in person, with an online option for those who cannot travel."</i></p>

          <p style="margin-top:100px;font-style:italic">Held in conjunction with the<br><a href="https://cvpr2022.thecvf.com/">IEEE Conference on Computer Vision and Pattern Recognition 2022.</a></p>
          <img src="img/logos/cvpr2022.png" width="50%">


        </div>
      </div>
    </header>

    <!-- About -->
    <section id="about" style="margin-top:0px;padding-top:0px;">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">About</h2>
          </div>
        </div>
        <div class="row text-left">
          <div class="col-lg-12 text-center">
            <p>Building on the success of the 1st workshop, the 2nd Workshop on Computer Vision in the Built Environment continous on connecting the domains of Architecture, Engineering, and Construction (AEC) with that of Computer Vision by establishing a common ground of interaction and identify shared research interests. . Specifically, this workshop focuses on the as-is semantic status of built environments and the changes that take place within them over time. These topics will be presented from the dual lens of Computer Vision and AEC-FM, highlighting the limitations and bottlenecks related to developing applications for this specific domain. The objective is for attendees to learn more about AEC-FM and the variety of real-world problems that, if solved, could have a tangible impact on this multi trillion dollar industry as well as the overall quality of life across the globe.</p>

            <p>The workshop will begin by establishing ways to acquire the as-is status of a space in a granular and hierarchical way - some of the speakers are experts in acquiring the spatial layout whereas others focus on object categories and their attributes. Building on this static scene understanding, we introduce the impact of time, as change that is either explicitly observed (a human interacting with an object) or implicitly inferred (capturing the as-is status of a scene in different timestamps). The combination of the static and dynamic understanding of 3D scenes is at the core of AEC-FM industry and currently missing. One example is that architects typically design living spaces without any feedback from their previous designs. Another example is that 5-12% (this percentage corresponds annually to billions of dollars in the US alone) of non-estimated construction cost is due to rework that originates from misinterpretation of design documents and the dynamically changing environment of construction sites.</p>

            <p>To further establish connections between the two domains and identify what we can do right now and what is still hard to solve, we will host the 2nd International Scan-to-BIM competition targeted on acquiring the semantic as-is status of buildings given their 3D point clouds. Specifically, we will focus on the tasks of floorplan reconstruction and 3D building model reconstruction and present appropriate interdisciplinary metrics for solving them. Last year we observed that a large gap remains before these problems can be considered solved and actually meet the needs of practitioners. We regard this workshop as the ideal environment for understanding the challenges and steps forward given that it provides convergence between the research and practical communities from multiple disciplines.</p>

          </div>
        </div>
       </div>
    </section>
    <!-- Schedule -->
    <section id="schedule">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Schedule</h2>
            <p><i>Times are in Central Standard Time zone</i></p>
          </div>
        </div>
        <div class="row text-center">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>TIME</b></p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><b>TOPIC</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><b>SPEAKERS</b><br>(tentative)</p>  
          </div>
        </div>
        <!-- Session 1 -->
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>09.00-09.30 AM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Introduction to the Workshop and Challenge</p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>09.30-10.00 AM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Lessons learned from decades of research in utilizing computer vision to support construction and infrastructure management, <i>Keynote Talk</i></p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#burcu">Prof. Burcu Akinci</a>, CEE, Carnegie Mellon University</p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>10.00-10.30 AM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Learning from Synthetic 3D Priors for Real-World 3D Perception, <i>Keynote Talk</i></p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#angela">Prof. Angela Dai</a>, CS, Technical University of Munich</p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>10.30-11.15 AM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Winner Presentations, Challenge I: Floorplan Reconstruction</p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>      
        </div>
        <!-- Coffee Break 1 -->
        <div class="row" style="background-color:#FFFFFF;color:#1F407A">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>11.15-11.30 AM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><i>Coffee Break</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p> 
          </div>
        </div>
        <!-- Session 2 -->
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>11.30-12.00 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Applying Machine Learning to Support Disaster Reconnaissance, <i>Keynote Talk</i></p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#shirley">Prof. Shirley Dyke</a>, ME-CE, Purdue University</p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>12.00-12.30 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Keynote Talk</p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#siyu">Prof. Siyu Tang</a>, CS, ETH Zurich</p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>12.30-1.15 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Winner Presentations, Challenge II: 3D Building Model Reconstruction</p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>      
        </div>
        <!-- Lunch Break -->
        <div class="row" style="background-color:#FFFFFF;color:#1F407A">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>1.15-2.15 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><i>Lunch Break</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p> 
          </div>
        </div>
        <!-- Session 3 -->
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>2.15-3.00 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Community Engagement</p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>3.00-3.30 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Weakly and Self Supervised Robot Perception: from Scene Understanding to Mobile Construction in AEC, <i>Keynote Talk</i></p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#chen">Prof. Chen Feng</a>, CUE-ME, New York University</p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>3.30-4.00 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Neural Scene Representations in Urban Environments, <i>Keynote Talk</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#thomas">Prof. Thomas Funkhouser</a>, CS, Google Researcher | Emeritus, Princeton University</p>
          </div>      
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>4.00-4.30 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>3D scene understanding with scene graphs and self-supervision  for AR and indoor design, <i>Keynote Talk</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#frederico">Dr. Federico Tombari</a>, CS, Google Research | Technical University of Munich</p>
          </div>      
        </div>
        <!-- Coffee Break 2 -->
        <div class="row" style="background-color:#FFFFFF;color:#1F407A">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>4.30-5.00 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><i>Coffee Break</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p> 
          </div>
        </div>
        <!-- Session 4 -->
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>5.00-5.45 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Panel Discussion</p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>5.45-6.00 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Conclusion Remarks</p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>
        </div>
      </div>
    </section>


<!-- Speakers -->
    <section id="speakers" style="background-color:#f2f1eb">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Speakers</h2>
          </div>
        </div>
        <!-- Speaker 1 -->
        <div class="row" style="margin-top:50px" id="burcu">
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_22/burcuakinci.jpg" alt="burcu_akinci">
              <h4><a href="https://www.cmu.edu/cee/people/faculty/akinci.html">Burcu Akinci</a></h4>
              <p class="text-muted">Professor, CEE, Carnegie Mellon University</p>
            </div>
          </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p><a href="https://www.cmu.edu/cee/people/faculty/akinci.html">Burcu Akinci</a> is Paul Christiano Professor of Civil & Environmental Engineering at Carnegie Mellon University and a member of the National Academies of Construction.  She was also former Associate Dean for Research for the College of Engineering and Director of Engineering Research Accelerator at Carnegie Mellon. She earned a bachelor’s degree in civil engineering from the Middle East Technical University (Ankara, Turkey), MBA from Bilkent University (Ankara, Turkey), and Master’s and PhD degrees in Civil and Environmental Engineering with a specialization in Construction Engineering and Management from Stanford University. Dr. Akinci’s research focuses on investigating utilization and integration of building information models with data capture technologies, such as 3D imaging and embedded sensors, to create digital twins of construction projects and infrastructure operations, and develop approaches to support proactive and predictive operations and management.
</p>
          </div>
        </div>
        <!-- Speaker 2 -->
        <div class="row" style="margin-top:50px" id='angela'>
           <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/angeladai.jpeg" alt="agnela_dai">
                <h4><a href="https://www.3dunderstanding.org/team.html">Angela Dai</a></h4>
                <p class="text-muted">Professor, CS, Technical University of Munich</p>
              </div>
            </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p><a href="https://www.3dunderstanding.org/team.html">Angela Dai</a> is an Assistant Professor at the Technical University of Munich. Her research focuses on understanding how the 3D world around us can be modeled and semantically understood, leveraging generative deep learning towards enabling understanding and interaction with real-world 3D/4D scenes for content creation and virtual or robotic agents. Previously, she received her PhD in computer science from Stanford in 2018 and her BSE in computer science from Princeton in 2013. Her research has been recognized through a ZDB Junior Research Group Award, an ACM SIGGRAPH Outstanding Doctoral Dissertation Honorable Mention, as well as a Stanford Graduate Fellowship.</p>
          </div>
        </div>
        <!-- Speaker 3 -->
        <div class="row" style="margin-top:50px" id='shirley'>
           <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/shirleydyke.jpg" alt="shirley_dyke">
                <h4><a href="https://engineering.purdue.edu/ME/People/ptProfile?resource_id=57291">Shirley J. Dyke</a></h4>
                <p class="text-muted">Professor, ME-CE, Purdue University</p>
              </div>
            </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p>Professor <a href="https://engineering.purdue.edu/ME/People/ptProfile?resource_id=57291">Shirley J. Dyke</a> holds a joint appointment in Mechanical Engineering and Civil Engineering at Purdue University. She is the Director of Purdue's Intelligent Infrastructure Systems Lab and the Director of the NASA funded Resilient ExtraTerrestrial Habitat Institute.  Dyke is the Editor-in-Chief of the journal Engineering Structures. Her research focuses on “intelligent” structures, and her innovations encompass structural health monitoring and machine learning for structural damage assessment and reconnaissance support. She holds a B.S. in Aeronautical and Astronautical Engineering from the University of Illinois, Champaign-Urbana in 1991 and a Ph.D. in Civil Engineering from the University of Notre Dame in 1996. She was awarded the Presidential Early Career Award for Scientists and Engineers from NSF (1998), the International Association on Structural Safety and Reliability Junior Research Award (2001) and the ANCRiSST Young Investigator Award (2006).</p>
          </div>
        </div>
        <!-- Speaker 4 -->
        <div class="row" style="margin-top:50px" id='chen'>
           <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/chenfeng.jpeg" alt="chen_feng">
                <h4><a href="https://engineering.nyu.edu/faculty/chen-feng">Chen Feng</a></h4>
                <p class="text-muted">Professor, CUE-ME, New York University</p>
              </div>
            </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p>Dr. Chen Feng is an assistant professor at NYU, appointed across departments including civil and mechanical engineering, and computer science. His lab AI4CE (pronounced as A-I-force) aims to advance robot vision and machine learning through multidisciplinary use-inspired research that originates from civil/mechanical engineering domains. Before NYU, Chen was a research scientist in the computer vision group at Mitsubishi Electric Research Labs (MERL) in Cambridge, MA, focusing on localization, mapping, and deep learning for self-driving cars and robotics. Chen holds a Bachelor's degree in geospatial engineering from Wuhan University in China, and a master’s degree in electrical engineering and a Ph.D. in civil engineering, both from the University of Michigan at Ann Arbor. More information can be found at <a href="https://ai4ce.github.io/">https://ai4ce.github.io/</a>.</p>
          </div>
        </div>
        <!-- Speaker 5 -->
        <div class="row" style="margin-top:50px" id='thomas'>
           <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/tomfunkhouser.jpeg" alt="tom_funkhouser">
                <h4><a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a></h4>
                <p class="text-muted">Senior Research Scientist, Google<br>Emeritus Professor, CS, Princeton University</p>
              </div>
            </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p>Thomas Funkhouser is a Senior Research Scientist in Google and the David M. Siegel Professor, Emeritus, at the CS Department, Princeton University. Thomas joined Princeton University in 1998 as an assistant professor. He became an associate professor in 2003 and a full professor in 2009.  Before coming to Princeton, he worked for four years on the technical staff at Bell Laboratories. He holds a Ph.D. in computer science from the University of California, Berkeley (1993), a Master’s in computer science from UCLA, and a Bachelor’s in biological sciences from Stanford. Among Professor Funkhouser’s honors and awards are the ACM SIGGRAPH Computer Graphics Achievement Award (2014), Sloan Foundation Fellowship (1999), and National Science Foundation Career Award (2000). </p>
          </div>
        </div>
        <!-- Speaker 6 -->
        <div class="row" style="margin-top:50px" id='siyu'>
           <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/siyutang.jpeg" alt="siyu_tang">
                <h4><a href="https://vlg.inf.ethz.ch/people/person-detail.siyutang.html">Siyu Tang</a></h4>
                <p class="text-muted">Professor, CS, ETH Zurich</p>
              </div>
            </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p>Siyu Tang is an assistant professor at ETH Zürich in the Department of Computer Science since January 2020. She received an early career research grant to start her own research group at the Max Planck Institute for Intelligent Systems in November 2017. She was a postdoctoral researcher in the same institute, advised by Dr. Michael Black. She finished her PhD at the Max Planck Institute for Informatics and Saarland University in 2017, under the supervision of Professor Bernt Schiele. Before that, she received her Master’s degree in Media Informatics at RWTH Aachen University, advised by Prof. Bastian Leibe and her Bachelor degree in Computer Science at Zhejiang University, China. She has received several awards for her research, including the Best Paper Award at BMVC 2012 and 3DV 2020, Best Paper Award Finalist at CVPR 2021, an ELLIS PhD Award and a DAGM-MVTec Dissertation Award.</p>
          </div>
        </div>
        <!-- Speaker 7 -->
        <div class="row" style="margin-top:50px" id='frederico'>
           <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/federicotombari.jpeg" alt="federico_tombari">
                <h4><a href="http://campar.in.tum.de/Main/FedericoTombari">Federico Tombari</a></h4>
                <p class="text-muted">Senior Research Scientist, Google<br>Lecturer, CS, Technical University of Munich</p>
              </div>
            </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p>Federico Tombari is Senior Staff Research Scientist and Manager at Google where he leads an applied research team in computer vision and ML. He is also a Lecturer (PrivatDozent) at the Technical University of Munich (TUM). He has 230+ peer-reviewed publications in CV/ML and applications to robotics, autonomous driving, healthcare and augmented reality. He got his PhD from the University of Bologna and his Habilitation from TUM. In 2018 he was co-founder and managing director of Pointu3D, a startup then acquired by Google. He regularly serves as Chair and Associate Editor for international conferences and journals (RA-L, ECCV18/22, IROS20/21/22, ICRA20/22, 3DV19/20/21 among others). He was the recipient of two Google Faculty Research Awards, one Amazon Research Award, 5 Outstanding Reviewer Awards (3x CVPR, ICCV21, NeuriIps21).</p>
          </div>
        </div>

   
      </div>
    </section>
        

    
      
  <!-- dates -->
    <section id="dates">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Important Dates</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-3 col-md-3 col-lg-3">
          </div>
          <div class="col-sm-7 col-md-7 col-lg-7">
            <ul>
              <li>Evaluation server open to evaluate test submissions: May 1st, 2022</li>
              <li>Challenge submission deadline: <span style="color:red;font-weight:bold;">June 12th, 2022 | 11:59 PM PDT</span></li>
              <li>Notification to participants:  June 15th, 2022</li>
              <li>Workshop day: <b>June 19, 2022, Sunday. Day 1 of CVPR 2022.</b></li>
            </ul>
          </div>
          <div class="col-sm-2 col-md-2 col-lg-2">
    </div>
          </div>
        </div>
      </div>
    </section>


    
    <!-- Challenge -->
    <section style="background-color:#f2f1eb" id="challenge">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Challenge</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-lg-12 text-center" style="margin-top:40px">
            <p>The workshop will host the 2nd International Scan-to-BIM challenge. The challenge will include the following tasks:</p>
            <p><b>I. Floorplan Reconstruction</b><br><b>II. 3D Building Model Reconstruction</b></p>
          </div>
        </div>
        <div class="row">   
          <div class="col-lg-12 text-center">
            <h4 class="section-heading text-uppercase text-center" style="margin-top:100px">Dataset</h4>
        <p>The 2D challenge is hosted on Codalab <b><a href="https://codalab.lisn.upsaclay.fr/competitions/4966">HERE</a></b>. The dataset can be downloaded from the challenge website. </p>
                        <p><b>Floorplan Reconstruction Task:</b></p>
            The 2D Floorplan Reconstruction challenge contains a total of 31 buildings with multiple floors each and dozens of rooms on each floor. Of which, 20 buildings are designated as the <i>training</i> set, with a total of 49 point clouds. The validation and testing 
sets contain 5.5 buildings with 21 point clouds each. For each model, there is a point cloud in LAZ format. For the training and validation sets, a corresponding floorplan aligned with the coordinate system of the point cloud is also provided.

            <p style="margin-top:10px"><b>File Specifications:</b> A description of the file formats and sample code to read/write these files can be found <b><a href="filespecs.html">HERE</a></b>.

            <p><b>3D Building Model Reconstruction Task:</b></p>
            <p> The 3D Challenge is now hosted as <a href="https://codalab.lisn.upsaclay.fr/competitions/5101"> a separate competition on Codalab</a> </p>
            <p> The training set is available to be downloaded from Codalab. The training data consists of 11 floors from 7 buildings. For each model, there is an 
aligned point cloud in LAZ format. The 3D building coordinates for walls, columns and doors are presented in 3 separate JSON files. The training data can be downloaded 
from the <b><a href="https://codalab.lisn.upsaclay.fr/competitions/5101">Codalab page</a></b> </p>
            <p> We decided to NOT provide proprietary formats such as Autodesk Revit files since there does not exist good open-source APIs to read them. The reason we decided not to provide an open format such as DXF is because 
DXF exports have arbitrary designations of conjunctions of walls, i.e. the corner will belong to only one of the walls in the DXF files, and the designation which corner
              belongs to which wall is arbitrary. 
            </p>
            <p> In our JSON format, we provide walls as middle lines + thickness. The middle lines will connect to each other at corners. Hence there is no ambiguity on which 
              part of the corner belongs to which wall. </p> 
            <p> We would like to note that ALL the submissions <b>need to be constructed automatically</b>. Manual reconstructions are against the spirit of this challenge and
              will not be allowed. </p>
            
            <p> The JSON files contain the following information: Model name, Number of layers. <br>
          For each layer, there is: Object type; Number of elements. <br> Details per element: <br>
Walls: object_type, endpoints (of raw middle lines), thickness, height, elevation if not encoded in the endpoints <br>
Doors/Columns: object_type, endpoint, thickness, height, elevation if not encoded in the endpoint <br> </p>


            <h4 class="section-heading text-uppercase text-center" style="margin-top:100px">Metrics</h4>
        <p>We will include metrics to evaluate the reconstruction of the walls, doors, and columns, as well as floor area in 2D.</p>
        <p><b>2D Evaluation Metrics</b></p>
        <p style="text-align:left;">
        <b>Geometric Metrics:</b><br/>
        <ul style="text-align:left;">
          <li><i>IoU</i> of the each room (a room is defined as a completely separated area with walls and doors).</li>
          <li><i>Accuracy of endpoints</i>. Precision/Recall at 3 different thresholds: 5cm, 10cm and 20cm, as well as the F-measure at each threshold will be evaluated in the coordinate system of the point cloud. The provided endpoints will be matched with the Hungarian algorithm to the point cloud, and every point that is within a certain threshold will be determined as a match.</li>
          <li><i>Orientation</i>. For each matched line between the ground truth, we will compute the cosine similarity metric between them as the normalized dot product. If a line is not matched with ground truth, the cosine metric will be zero. Finally, the metric will be averaged over all the ground truth lines.</li>
        </ul>
        </p>
        <p style="text-align:left;">
        <b>Topological Metrics:</b><br/>
        We will also evaluate topological metrics that measure whether the connectivity of the rooms match the ground truth.
        <ul style="text-align:left;">
          <li><i>Warping error(<a href="https://ieeexplore.ieee.org/document/5539950">Jain et al. 2010</a>).</i>The warping error will first warp the predicted floorplan to the ground truth with a homotopic deformation, and then compute the pixels that cannot match after the deformation.</li>
          <li><i>Betti number error.</i>The Betti number error will compare the Betti numbers between the prediction and the ground truth and output the absolute value of the difference.</li>
        </ul>
        </p>
            <p><b>3D Evaluation Metrics</b></p>
        <p style="text-align:left;">
        <b> Geometric Metrics: </b><br/>
        <ul style="text-align:left;">
          <li><i>3D IoU</i> of the 3D bounding box of each wall. </li>
          <li><i>Accuracy of the endpoints</i>. Precition/Recall at 3 different thresholds: 5cm, 10cm and 20cm, as well as F-measure will be evaluated in the coordinate system of the point cloud. The provided endpoints will be matched with the Hungarian algorithm to the point cloud, and every point that is within a certain threshold will be determined as a match.</li>
            <p style="text-align:left;"></p>

      
        <h4 class="section-heading text-uppercase text-center" style="margin-top:100px">Evaluation and Submission</h4>
        <p> The evaluation code for the 2D floorplan task is available from <a href="https://github.com/seravee08/WarpingError_Floorplan">This GitHub Repository</a>. </p>
        <p>Submission of results on the testing set and evaluation on the ground truth data will be available on the Codalab <a href="https://codalab.lisn.upsaclay.fr/competitions/4966">evaluation server</a>. For 2D, the submission will be
          in the same JSON format as in the ground truth provided to you. </p>
        <p>The evaluation code for the 3D building reconstruction task is available from <a href="https://github.com/arkhodakov/cvpr-2022-matching/">This GitHub Repository</a>. 
          For 3D entries, the submission will be in the same JSON format as provided to the <a href="https://codalab.lisn.upsaclay.fr/competitions/5101">3D Codalab evaluation server</a> .</p>
                  
            <h4 class="section-heading text-uppercase text-center" style="margin-top:100px">Questions?</h4>
            <p>Contact the organizers at: <a href="mailto:cv4aec.3d@gmail.com">cv4aec.3d@gmail.com</a></p>
          </div>
        </div>
      </div>
    </section>


    <!-- Organizers -->
    <section id="organizers">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Organizers</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_22/iroarmeni.jpg" alt="iro_armeni">
              <h4><a href="https://cs.stanford.edu/~iarmeni/">Iro Armeni</a></h4>
              <p class="text-muted">Postdoctoral Researcher, ETHZ</p>
            </div>
          </div>
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_22/erzhuoche.jpeg" alt="erzhuo_che">
              <h4><a href="https://cce.oregonstate.edu/people/erzhuo-che">Erzhuo Che</a></h4>
              <p class="text-muted">Professor, CEE, Oregon State</p>
            </div>
          </div>
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_22/martinfischer.jpg" alt="martin_fischer">
              <h4><a href="https://web.stanford.edu/~fischer/">Martin Fischer</a></h4>
              <p class="text-muted">Professor, CEE, Stanford</p>
            </div>
          </div>
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_22/yasufurukawa.jpg" alt="yasu_furukawa">
              <h4><a href="https://www.cs.sfu.ca/~furukawa/">Yasutaka Furukawa</a></h4>
              <p class="text-muted">Professor, CS, Simon Fraser</p>
            </div>
          </div>
        </div>
        <div class="row">
            <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/danielhall.jpeg" alt="daniel_hall">
                <h4><a href="https://ic.ibi.ethz.ch/people/prof-dr-daniel-hall.html">Daniel Hall</a></h4>
                <p class="text-muted">Professor, CEE, ETHZ</p>
              </div>
            </div>
            <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/jaehoonjung.jpeg" alt="jaehoon_jung">
                <h4><a href="https://cce.oregonstate.edu/people/jaehoon-jung">Jaehoon Jung</a></h4>
                <p class="text-muted">Professor, CEE, Oregon State</p>
              </div>
          </div>
          <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/fuxinli.jpg" alt="fuxin_li">
                <h4><a href="http://web.engr.oregonstate.edu/~lif/">Fuxin Li</a></h4>
                <p class="text-muted">Professor, CS, Oregon State</p>
              </div>
          </div>
            <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/michaelolsen.jpg" alt="michael_olsen">
                <h4><a href="https://cce.oregonstate.edu/olsen">Michael Olsen</a></h4>
                <p class="text-muted">Professor, CEE, Oregon State</p>
              </div>
            </div>
    </div>
        <div class="row">
          <div class="col-sm-3 col-md-3 col-lg-3">            
          </div>
            <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/marcpollefeys.jpeg" alt="marc_pollefeys">
                <h4><a href="http://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a></h4>
                <p class="text-muted">Professor, CS, ETHZ</p>
              </div>
            </div>
          <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_22/yeldaturkan.jpg" alt="yelda_turkan">
                <h4><a href="https://cce.oregonstate.edu/turkan">Yelda Turkan</a></h4>
                <p class="text-muted">Professor, CEE, Oregon State</p>
              </div>
          </div>
          <div class="col-sm-3 col-md-3 col-lg-3">            
          </div>
        </div>
      </div>
    </section>


    <!-- Footer -->
    <footer style="background-color:#f2f1eb">
      <div class="container">
        <div class="row">
          <div class="col-sm-4 col-md-4 col-lg-4">
            <a href="https://oregonstate.edu/">
                  <img src="img/logos/oregon_state.png" alt="oregon_state" style="height:50px">
            </a>
          </div>
          <div class="col-sm-4 col-md-4 col-lg-4">
            <a href="https://ethz.ch/en.html">
                  <img src="img/logos/ethz.png" alt="ethz" style="height:50px">
            </a>
          </div>
          <div class="col-sm-4 col-md-4 col-lg-4">
            <a href="https://www.stanford.edu/">
                  <img src="img/logos/stanford.png" alt="stanford" style="height:80px">
            </a>
          </div>
        </div>
      </div>
    </footer>


    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Contact form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/agency.min.js"></script>

  </body>

</html>
