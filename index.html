<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Computer Vision in the Built Environment</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>
    <!-- Custom styles for this template -->
    <link href="css/agency.min.css" rel="stylesheet">
    <link rel="stylesheet" href="css/table.css">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="index.html">Computer Vision in the Built Environment</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav text-uppercase ml-auto text-center">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#description"><b>About</b></a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#challenge"><b>Challenge</b></a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#schedule"><b>Schedule</b></a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#speakers"><b>Speakers</b></a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#organizers"><b>Organizers</b></a>
            </li>
            <li class="nav-item">
              <div class="dropdown">
                <a class="nav-link js-scroll-trigger"><b>Previous Workshops</b></a>
                <div class="dropdown-content">
                  <a class="nav-link js-scroll-trigger" href="index_2022.html">2022</a></br>
                  <a class="nav-link js-scroll-trigger" href="index_2021.html">2021</a> 
                </div>
              </div>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Header -->
    <header class="masthead">
      <div class="container">
        <div class="intro-text">
          <div class="intro-lead-in">3rd Workshop and Challenge on</div>
          <div class="intro-heading text-uppercase"><span style="font-weight:600">Computer Vision in the Built Environment</span><br> <span style="text-transform:lowercase;font-style:italic">for the</span> Design, Construction, <span style="text-transform:lowercase;font-style:italic">and</span> Operation of Buildings</div>
          
          <div class="intro-lead-in" style="margin-bottom:0px;padding-bottom:0px;">June 18th 2023, Full Day Workshop</div> 

          <p style="margin-top:50px;color:red">News: Codalab links will be added soon.</p>

          <p style="margin-top:100px;font-style:italic">Held in conjunction with the<br><a href="https://cvpr2023.thecvf.com/">IEEE Conference on Computer Vision and Pattern Recognition 2023.</a></p>
          <img src="img/logos/cvpr2023.png" width="50%">


        </div>
      </div>
    </header>

    <!-- About -->
    <section id="about" style="background-color:#f2f1eb">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">About</h2>
          </div>
        </div>
        <div class="row text-left">
          <div class="col-lg-12 text-center">
            <p>Building on the success of the previous two workshops, the 3rd Workshop on Computer Vision in the Built Environment continues on connecting the domains of Architecture, Engineering, and Construction (AEC) with that of Computer Vision by establishing a common ground of interaction and identify shared research interests. Specifically, this workshop focuses on the as-is semantic status of built environments and the changes that take place within them over time. These topics will be presented from the dual lens of Computer Vision and AEC-FM, highlighting the limitations and bottlenecks related to developing applications for this specific domain. The objective is for attendees to learn more about AEC-FM and the variety of real-world problems that, if solved, could have a tangible impact on this multi trillion dollar industry as well as the overall quality of life across the globe.</p>

            <p>The workshop will begin by establishing ways to capture the as-is status of a space with expert speakers from both the AEC and Computer Vision domains. Attendees will be then introduced to the type of information required for the spatiotemporal analysis of our built environment in AEC, with a focus on effective management, safety, and the role of users in this process. Following that, the topic of scene understanding from 3D and 4D reconstructions will be presented. Finally, to close the loop from understanding real-world built environments to designing built environments better and faster, the topic of scene synthesis at a geometric and semantic level will be presented. The importance of closing the loop for the AEC industry is paramount, especially when considering the design paradox. Architects are designing living spaces without any feedback from their previous designs. Learning to design using data from spaces that are already occupied and in-use, can provide designers with insights on what makes spaces appropriate for supporting the quality of life of the users.</p>

            <p>To further establish connections between the two domains and identify what we can do right now and what is still hard to solve, we will host the 3rd International Scan-to-BIM competition targeted on acquiring the semantic as-is status of buildings given their 3D point clouds. Specifically, we will focus on the tasks of floorplan reconstruction and 3D building model reconstruction and present appropriate interdisciplinary metrics for solving them. The past two years we observed that a large gap remains before these problems can be considered solved and actually meet the needs of practitioners. We regard this workshop as the ideal environment for understanding the challenges and steps forward given that it provides convergence between the research and practical communities from multiple disciplines.</p>

          </div>
        </div>
       </div>
    </section>


    <section id="schedule">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Schedule</h2>
            <p><i>Times are in Central Standard Time zone</i></p>
          </div>
        </div>

        <div class="row text-center">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>TIME</b></p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><b>TOPIC</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><b>SPEAKERS</b></p>  
          </div>
        </div>
        
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>09.00-09.30 AM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Introduction to the Workshop and Challenge</p>
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>09.30-10.00 AM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>TBD, <i>Keynote Talk</i></p>
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#avideh">Prof. Avideh Zakhor</a>, EE & CS, University of California Berkeley</p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>10.00-10.30 AM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Computer Vision and Multi-Source Data-Driven Simulations for Safe and Efficient Operations of Aging Civil Infrastructure, <i>Keynote Talk</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#pingbo">Prof. Pingbo Tang</a>, CEE, Carnegie Mellon University</p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>10.30-11.15 AM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Winner Presentations, Challenge I: Floorplan Reconstruction</p>
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>      
        </div>
        
        <div class="row" style="background-color:#FFFFFF;color:#1F407A">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>11.15-11.30 AM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><i>Coffee Break</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p> 
          </div>
        </div>
        
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>11.30-12.00 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>TBD, <i>Keynote Talk</i></p>
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#manmohan">Prof. Manmohan Chandraker</a>, CSE, University of California San Diego</p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>12.00-12.30 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>TBD, <i>Keynote Talk</i></p>
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#mani">Prof. Mani Golparvar Fard</a>, CEE, University of Illinois Urbana-Champaign</p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>12.30-1.15 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Winner Presentations, Challenge II: 3D Building Model Reconstruction</p>
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>      
        </div>
        
        <div class="row" style="background-color:#FFFFFF;color:#1F407A">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>1.15-2.15 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><i>Lunch Break</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p> 
          </div>
        </div>
        
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>2.15-3.00 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Community Engagement</p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>3.00-3.30 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Learning to generate and manipulate 3D environments, <i>Keynote Talk</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#despoina">Dr. Despoina Paschalidou</a>, CS, Stanford University</p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>3.30-4.00 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>TBD, <i>Keynote Talk</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="#fernanda">Prof. Fernanda Leite</a>, CAEE, University of Texas Austin</p>
          </div>      
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>4.00-4.30 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>TBD, <i>Keynote Talk</i></p>
            <p></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>TBD</p>
          </div>      
        </div>

        <div class="row" style="background-color:#FFFFFF;color:#1F407A">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>4.30-5.00 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><i>Coffee Break</i></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p> 
          </div>
        </div>
        
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>5.00-5.45 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p><a href="https://oregonstate.box.com/s/aj0hcbq9h7dbamuxti899ircets7oe6l">Panel Discussion</p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-2 col-md-2 col-lg-2">
            <p><b>5.45-6.00 PM : &nbsp&nbsp</b></p> 
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p>Conclusion Remarks</p>  
          </div>
          <div class="col-sm-5 col-md-5 col-lg-5">
            <p></p>
          </div>
        </div>
      </div>
    </section>


    
    <section id="speakers" style="background-color:#f2f1eb">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Speakers</h2>
          </div>
        </div>
        <!-- Speaker 1 -->
        <div class="row" style="margin-top:50px" id="manmohan">
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_23/manmohan_chandraker.jpg" alt="manmohan_chandraker">
              <h4><a href="https://cseweb.ucsd.edu/~mkchandraker/">Manmohan Chandraker</a></h4>
              <p class="text-muted">Professor, CSE, University of California San Diego</p>
            </div>
          </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p><a href="https://cseweb.ucsd.edu/~mkchandraker/">Manmohan Chandraker</a> is an associate professor at the CSE department of the University of California, San Diego. His research interests are in computer vision, machine learning and graphics-based vision, with applications to autonomous driving and augmented reality. His works have received the Marr Prize Honorable Mention for Best Paper at ICCV 2007, the 2009 CSE Dissertation Award for Best Thesis at UCSD, a PAMI special issue on best papers of CVPR 2011, the Best Paper Award at CVPR 2014, the 2018 NSF CAREER Award and the 2018 and 2019 Google Daydream Research Award. He serves as an Area Chair at CVPR, ICCV, ECCV, ICVGIP and AAAI.</p>
          </div>
        </div>

      <!-- Speaker 2 -->
      <div class="row" style="margin-top:50px" id="mani">
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_23/mani_golparvar.jpg" alt="mani_golparvar">
              <h4><a href="https://cee.illinois.edu/directory/profile/mgolpar">Mani Golparvar Fard</a></h4>
              <p class="text-muted">Professor, CEE, University of Illinois Urbana-Champaign</p>
            </div>
          </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p><a href="https://cee.illinois.edu/directory/profile/mgolpar">Mani Golparvar Fard</a> is a Professor of Civil Engineering and Computer Science & Technology Entrepreneurship. He is a Faculty Entrepreneurial Fellow, Excellence Faculty Fellow, and the director of the Real-time and Automated Monitoring and Control (RAAMAC) lab at the University of Illinois at Urbana-Champaign (UIUC). He received his Ph.D. degree in Civil Engineering and MS degree in Computer Science from UIUC in 2010, MASc in Civil Engineering from the University of British Columbia in 2006, and MS and BS in Civil Engineering from Iran University of Science and Technology in 2005 and 2002 respectively. Prior to joining the faculty at UIUC, he was an Assistant Professor in Civil Engrg at Virginia Tech. Dr. Golparvar has worked with many national and international construction companies and most extensively with Turner Construction. Dr. Golparvar-Fard has several patents and is currently involved with Reconstruct Inc., an early-stage technology company with $28 million in venture capital funding that was founded based on the outcomes of his ongoing research projects.</p>
          </div>
        </div>

      <!-- Speaker 3 -->
      <div class="row" style="margin-top:50px" id="fernanda">
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_23/fernanda_leite.jpg" alt="fernanda_leite">
              <h4><a href="https://www.caee.utexas.edu/people/faculty/faculty-directory/leite">Fernanda Leite</a></h4>
              <p class="text-muted">Professor, CAEE, University of Texas Austin</p>
            </div>
          </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p><a href="https://www.caee.utexas.edu/people/faculty/faculty-directory/leite">Fernanda Leite</a> a Professor in the Cockrell School of Engineering at the University of Texas at Austin. She holds the John A. Focht Centennial Teaching Fellowship in Civil Engineering. She combines expertise in architectural engineering and computing in her modeling and built environment research. She is an Associate Editor for the journal Automation in Construction. Most of her work has been in building and infrastructure systems information modeling, visualization and collaboration technologies, and circular economy in the built environment. At UT-Austin, Dr. Leite teaches courses on Building Information Modeling, Project Management and Economics, Construction Safety, and Sustainable Systems Engineering.</p>
          </div>
      </div>

      <!-- Speaker 4 -->
      <div class="row" style="margin-top:50px" id="despoina">
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_23/despoina_paschalidou.jpg" alt="despoina_paschalidou">
              <h4><a href="https://paschalidoud.github.io/">Despoina Paschalidou</a></h4>
              <p class="text-muted">Postdoctoral Researcher, CS, Stanford University</p>
            </div>
          </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p><a href="https://paschalidoud.github.io/">Despoina Paschalidou</a> is a PostDoc at Stanford University working with Prof. Leo Guibas at the Geometric Computation Group. Prior to this, she did her PhD at the Max Planck Institute for Intelligent Systems in Tubingen and the Computer Vision Lab in ETH Zurich, under the guidance of Prof. Andreas Geiger and Prof. Luc van Gool. She received her Diploma in Electrical and Computer Engineering from the Aristotle University of Thessaloniki, in 2015. Her research interests revolve around editable and interpretable representations of 3D objects and scenes. She spent 1 year working with Prof. Sanja Fidler at NVIDIA Research on developing interactive tools for content creation. Moreover, she spent 6 months at FAIR working with Prof. Andrea Vedaldi and David Novotny on unsupervised 3D reconstruction from video data.</p>
          </div>
      </div>

      <!-- Speaker 5 -->
      <div class="row" style="margin-top:50px" id="pingbo">
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_23/pingbo_tang.jpg" alt="pingbo_tang">
              <h4><a href="https://www.cmu.edu/cee/people/faculty/tang.html">Pingbo Tang</a></h4>
              <p class="text-muted">Professor, CEE, Carnegie Mellon University</p>
            </div>
          </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p><a href="https://www.cmu.edu/cee/people/faculty/tang.html">Pingbo Tang</a> is an associate professor in the Department of Civil and Environmental Engineering. He founded and is directing Spatiotemporal Workflows and Resilient Management Laboratory (SWARM Lab). He obtained his Bachelor’s Degree in Civil Engineering in 2002, and his Master’s Degree in Bridge Engineering in 2005, both from Tongji University, Shanghai, China. He obtained his Ph.D. from the group of Advanced Infrastructure Systems (AIS) at Carnegie Mellon University in 2009. Tang is an expert on civil infrastructure operations and human systems engineering for civil infrastructure operational safety. His research explores remote sensing, human systems engineering, and information modeling technology in support of the spatiotemporal analyses needed for the effective management of workspaces, constructed facilities, and civil infrastructure systems. His ongoing studies have been examining sensing and modeling methods for comprehending the Human-Cyber-Physical-Systems (H-CPS) in accelerated construction and infrastructure operations (e.g., airport operations, power plant operations, water treatment plant control). He has published more than 100 peer-reviewed articles in these areas. The National Science Foundation (NSF), Department of Energy (DOE), The National Aeronautics and Space Administration (NASA), and the industry have funded his research efforts.</p>
          </div>
      </div>

      <!-- Speaker 6 -->
      <div class="row" style="margin-top:50px" id="avideh">
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_23/avideh_zakhor.jpg" alt="avideh_zakhor">
              <h4><a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/zakhor.html">Avideh Zakhor</a></h4>
              <p class="text-muted">Professor, EE & CS, University of California Berkeley</p>
            </div>
          </div>
          <div class="col-sm-9 col-md-9 col-lg-9">
            <p><a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/zakhor.html">Avideh Zakhor</a> is a professor of electrical engineering and computer science at the University of California at Berkeley (Berkeley) where she holds the Qualcomm chair. Prof. Zakhor’s research is focused on 3D computer vision, reality capture for augmented and virtual reality, sensor fusion, and application of deep learning to signal, image and video processing. Dr. Zakhor is the recipient of multiple awards underscoring both her academic and professional qualifications including the winner of phase 1 and 2 of U.S. Department of Energy sponsored E-Robot project in 2021 and 2022. She is a fellow of IEEE and was chosen as the  SPIE Electronic Imaging Scientist of the Year  in 2018. Dr. Zakhor has spun off numerous startups from her lab at UC Berkeley. In 2005, she co-founded UrbanScan to commercialize software/hardware systems for rapid 3D, automated 3D modeling of cities, which became part of Google Earth product when UrbanScan was acquired by Google (Nasdaq;GOOG) in 2007. In 2015, she founded Indoor Reality  to develop 3D indoor mapping technologies for fast, automated, visual documentation, asset management, and energy audits of existing buildings. Indoor Reality was acquired by a large multi-billion dollar construction supplies company in 2019.</p>
          </div>
      </div>
    </section>


    <!-- recordings
    <section id="recordings" style="background-color:#f2f1eb">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Workshop 2023 Recordings</h2>
          </div>
        </div>
        
        <div class="row" style="margin-bottom:50px">
          <div class="col-sm-1 col-md-1 col-lg-1">
        </div>
        <div class="col-lg-12 text-center" style="margin-top:40px">
          <a href="" style="display:inline-block">Click Here</a>
        </div>
    
    </section>
    -->

    <section id="dates">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Important Dates</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-3 col-md-3 col-lg-3">
          </div>
          <div class="col-sm-7 col-md-7 col-lg-7">
            <ul>
              <li>Evaluation server open to evaluate test submissions: TBD</li>
              <li>Challenge submission deadline: TBD</li>
              <li>Notification to participants:  TBD</li>
              <li>Workshop day: <b>June 18, 2023, Monday. Day 1 of CVPR 2023.</b></li>
            </ul>
          </div>
          <div class="col-sm-2 col-md-2 col-lg-2">
          </div>
          </div>
        </div>
    </section>


    

    <section style="background-color:#f2f1eb" id="challenge">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Challenge</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-lg-12 text-center" style="margin-top:40px">
            <p>The workshop will host the 3rd International Scan-to-BIM challenge. The challenge will include the following tasks:</p>
            <p>
              <b>I. Floorplan Reconstruction</b><br>
              <b>II. 3D Building Model Reconstruction</b>
            </p>
          </div>
        </div>
        <div class="row">   
          <div class="col-lg-12 text-center">
            <h4 class="section-heading text-uppercase text-center" style="margin-top:100px">Dataset</h4>
              <p>The 2D challenge is hosted on Codalab <b><a href="">HERE</a></b>. The dataset can be downloaded from the challenge website. </p>
              <p><b>Floorplan Reconstruction Task:</b></p>
              <p>The 2D Floorplan Reconstruction challenge contains a total of 31 buildings with multiple floors each and dozens of rooms on each floor. Of which, 20 buildings are designated as the <i>training</i> set, with a total of 49 point clouds. The validation and testing sets contain 5.5 buildings with 21 point clouds each. For each model, there is an aligned point cloud in LAZ format. For the training and validation sets, a corresponding floorplan aligned with the coordinate system of the point cloud is also provided.<br>
              <b>File Specifications:</b> A description of the file formats and sample code to read/write these files can be found <b><a href="filespecs.html">HERE</a></b>.

              <br><br>
              <p><b>3D Building Model Reconstruction Task:</b></p>
              <p> The 3D Challenge is now hosted as a separate competition on Codalab <b><a href="">HERE</a></b>. The dataset can be downloaded from the challenge website.</p>
              <p>The 3D Building Model Reconstruction challenge contains a total of 28 floors from 17 buildings. Of which, 13 buildings are designated as the <i>training</i> set, with a total of 21 point clouds. For each model, there is an aligned point cloud in LAZ format. We focus on the reconstruction of walls, columns, and doors.<br>
              <b>File Specifications:</b> A description of the file contents can be found <b><a href="filespecs.html#3dchallenge">HERE</a></b>.
              


            <h4 class="section-heading text-uppercase text-center" style="margin-top:100px">Metrics</h4>
            <p>We will include metrics to evaluate the reconstruction of the walls, doors, and columns, as well as floor area in 2D.</p>

            <p><b>2D Evaluation Metrics</b></p>
            <p style="text-align:left;">
            <b>Geometric Metrics:</b><br/>
            <ul style="text-align:left;">
              <li><i>IoU</i> of the each room (a room is defined as a completely separated area with walls and doors).</li>
              <li><i>Accuracy of endpoints</i>. Precision/Recall at 3 different thresholds: 5cm, 10cm and 20cm, as well as the F-measure at each threshold will be evaluated in the coordinate system of the point cloud. The provided endpoints will be matched with the Hungarian algorithm to the point cloud, and every point that is within a certain threshold will be determined as a match.</li>
              <li><i>Orientation</i>. For each matched line between the ground truth, we will compute the cosine similarity metric between them as the normalized dot product. If a line is not matched with ground truth, the cosine metric will be zero. Finally, the metric will be averaged over all the ground truth lines.</li>
            </ul>
            </p>
            <p style="text-align:left;">
            <b>Topological Metrics:</b><br/>
            We will also evaluate topological metrics that measure whether the connectivity of the rooms match the ground truth.
            <ul style="text-align:left;">
              <li><i>Warping error(<a href="https://ieeexplore.ieee.org/document/5539950">Jain et al. 2010</a>).</i>The warping error will first warp the predicted floorplan to the ground truth with a homotopic deformation, and then compute the pixels that cannot match after the deformation.</li>
              <li><i>Betti number error.</i>The Betti number error will compare the Betti numbers between the prediction and the ground truth and output the absolute value of the difference.</li>
            </ul>
            </p>
            
            <p><b>3D Evaluation Metrics</b></p>
            <p style="text-align:left;">
            <b> Geometric Metrics: </b><br/>
            <ul style="text-align:left;">
              <li><i>3D IoU</i> of the 3D bounding box of each wall. </li>
              <li><i>Accuracy of the endpoints</i>. Precition/Recall at 3 different thresholds: 5cm, 10cm and 20cm, as well as F-measure will be evaluated in the coordinate system of the point cloud. The provided endpoints will be matched with the Hungarian algorithm to the point cloud, and every point that is within a certain threshold will be determined as a match. We evaluate per each of the three semantic types (i.e., <i>wall</i>, <i>column</i>, <i>door</i>).</li>
            </p>

      
        <h4 class="section-heading text-uppercase text-center" style="margin-top:100px">Evaluation and Submission</h4>
        <p> We would like to note that ALL the submissions <b>need to be constructed automatically</b>. Manual reconstructions are against the spirit of this challenge and will not be allowed. </p>
        <p><b>2D Floorplan Reconstruction:</b> The evaluation code for the 2D floorplan task is available from <a href="https://github.com/seravee08/WarpingError_Floorplan">This GitHub Repository</a>. Submission of results on the testing set and evaluation on the ground truth data will be available on the <a href="">2D Codalab evaluation server</a>. The submission will be in the same JSON format as in the ground truth provided to you.</p>
        <p><b>3D Building Model Reconstruction:</b> The evaluation code for the 3D building reconstruction task is available from <a href="https://github.com/arkhodakov/cvpr-2022-matching/">This GitHub Repository</a>. The submission will be in the same JSON format as provided at the <a href="">3D Codalab evaluation server</a>.</p>
                 
          
            <h4 class="section-heading text-uppercase text-center" style="margin-top:100px">Questions?</h4>
            <p>Contact the organizers at: <a href="mailto:cv4aec.3d@gmail.com">cv4aec.3d@gmail.com</a></p>
          </div>
        </div>
      </div>
    </section>
    -->


    <!-- Organizers -->
    <section id="organizers">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Organizers</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_23/iroarmeni.jpg" alt="iro_armeni">
              <h4><a href="https://cs.stanford.edu/~iarmeni/">Iro Armeni</a></h4>
              <p class="text-muted">Postdoctoral Researcher, ETHZ</p>
            </div>
          </div>
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_23/erzhuoche.jpeg" alt="erzhuo_che">
              <h4><a href="https://cce.oregonstate.edu/people/erzhuo-che">Erzhuo Che</a></h4>
              <p class="text-muted">Professor, CEE, Oregon State</p>
            </div>
          </div>
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_23/martinfischer.jpg" alt="martin_fischer">
              <h4><a href="https://web.stanford.edu/~fischer/">Martin Fischer</a></h4>
              <p class="text-muted">Professor, CEE, Stanford</p>
            </div>
          </div>
          <div class="col-sm-3 col-md-3 col-lg-3">
            <div class="team-member">
              <img class="mx-auto rounded-circle" src="img/people_23/yasufurukawa.jpg" alt="yasu_furukawa">
              <h4><a href="https://www.cs.sfu.ca/~furukawa/">Yasutaka Furukawa</a></h4>
              <p class="text-muted">Professor, CS, Simon Fraser</p>
            </div>
          </div>
        </div>
        <div class="row">
            <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_23/danielhall.jpeg" alt="daniel_hall">
                <h4><a href="https://ic.ibi.ethz.ch/people/prof-dr-daniel-hall.html">Daniel Hall</a></h4>
                <p class="text-muted">Professor, CEE, ETHZ</p>
              </div>
            </div>
            <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_23/jaehoonjung.jpeg" alt="jaehoon_jung">
                <h4><a href="https://cce.oregonstate.edu/people/jaehoon-jung">Jaehoon Jung</a></h4>
                <p class="text-muted">Professor, CEE, Oregon State</p>
              </div>
          </div>
          <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_23/fuxinli.jpg" alt="fuxin_li">
                <h4><a href="http://web.engr.oregonstate.edu/~lif/">Fuxin Li</a></h4>
                <p class="text-muted">Professor, CS, Oregon State</p>
              </div>
          </div>
            <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_23/michaelolsen.jpg" alt="michael_olsen">
                <h4><a href="https://cce.oregonstate.edu/olsen">Michael Olsen</a></h4>
                <p class="text-muted">Professor, CEE, Oregon State</p>
              </div>
            </div>
    </div>
        <div class="row">
          <div class="col-sm-3 col-md-3 col-lg-3">            
          </div>
            <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_23/marcpollefeys.jpeg" alt="marc_pollefeys">
                <h4><a href="http://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a></h4>
                <p class="text-muted">Professor, CS, ETHZ</p>
              </div>
            </div>
          <div class="col-sm-3 col-md-3 col-lg-3">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/people_23/yeldaturkan.jpg" alt="yelda_turkan">
                <h4><a href="https://cce.oregonstate.edu/turkan">Yelda Turkan</a></h4>
                <p class="text-muted">Professor, CEE, Oregon State</p>
              </div>
          </div>
          <div class="col-sm-3 col-md-3 col-lg-3">            
          </div>
        </div>
      </div>
    </section>


    <!-- Footer -->
    <footer style="background-color:#f2f1eb">
      <div class="container">
        <div class="row">
          <div class="col-sm-4 col-md-4 col-lg-4">
            <a href="https://oregonstate.edu/">
                  <img src="img/logos/oregon_state.png" alt="oregon_state" style="height:50px">
            </a>
          </div>
          <div class="col-sm-4 col-md-4 col-lg-4">
            <a href="https://ethz.ch/en.html">
                  <img src="img/logos/ethz.png" alt="ethz" style="height:50px">
            </a>
          </div>
          <div class="col-sm-4 col-md-4 col-lg-4">
            <a href="https://www.stanford.edu/">
                  <img src="img/logos/stanford.png" alt="stanford" style="height:80px">
            </a>
          </div>
        </div>
      </div>
    </footer>


    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Contact form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/agency.min.js"></script>

  </body>

</html>
